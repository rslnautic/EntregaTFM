{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.4,org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4,org.elasticsearch:elasticsearch-hadoop:7.4.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import json\n",
    "import kafka\n",
    "from ast import literal_eval\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SparkContext \n",
    "from pyspark.streaming import StreamingContext \n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"es.index.auto.create\", \"true\").appName(\"SSKafka\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"test_agg\") \\\n",
    "  .load()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "message.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(stock,StringType,true),StructField(date,StringType,true),StructField(prices,ArrayType(DoubleType,true),true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "            StructField(\"stock\", StringType(), True),\n",
    "            StructField(\"date\", StringType(), True),\n",
    "            StructField(\"prices\", ArrayType(DoubleType()), True)])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- stock: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- prices: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stockValue = message.select(from_json(col(\"value\"), schema).alias(\"data\")).select(\"data.*\")\n",
    "stockValue.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- stock: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- n5: double (nullable = true)\n",
      " |-- n4: double (nullable = true)\n",
      " |-- n3: double (nullable = true)\n",
      " |-- n2: double (nullable = true)\n",
      " |-- n1: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stockValueFinal = stockValue.select(\"stock\", \"date\", stockValue.prices[0].alias(\"n5\"), stockValue.prices[1].alias(\"n4\"), stockValue.prices[2].alias(\"n3\"), stockValue.prices[3].alias(\"n2\"), stockValue.prices[4].alias(\"n1\"))\n",
    "stockValueFinal.printSchema()\n",
    "#stockValueFinal.writeStream.format(\"parquet\").option(\"path\", \"/tmp/test2\").option(\"checkpointLocation\", \"checkpoint\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineModel.load(\"FINAL_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_d71c425ebdd0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- stock: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- n5: double (nullable = true)\n",
      " |-- n4: double (nullable = true)\n",
      " |-- n3: double (nullable = true)\n",
      " |-- n2: double (nullable = true)\n",
      " |-- n1: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.transform(stockValueFinal)\n",
    "prediction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.writeStream.format(\"parquet\").option(\"path\", \"/tmp/test\").option(\"checkpointLocation\", \"checkpoint\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asd = prediction.selectExpr(\"CAST(stock AS STRING) AS key\", \"to_json(struct(*)) AS value\")\n",
    "asd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.selectExpr(\"key\", \"value\") \\\n",
    "   .writeStream \\\n",
    "   .format(\"kafka\") \\\n",
    "   .outputMode(\"append\") \\\n",
    "   .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "   .option(\"topic\", \"testoutput\") \\\n",
    "   .option(\"checkpointLocation\", \"checkpoint10\") \\\n",
    "   .start() \\\n",
    "   .awaitTermination() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.selectExpr(\"key\", \"value\") \\\n",
    "   .writeStream \\\n",
    "   .format(\"es\") \\\n",
    "   .outputMode(\"append\") \\\n",
    "   .option(\"checkpointLocation\", \"checkpoint2\") \\\n",
    "   .option(\"es.resources\", \"data\") \\\n",
    "   .option(\"es.nodes\", \"localhost\") \\\n",
    "   .start(\"data/doc-type\") \\\n",
    "   .awaitTermination() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
